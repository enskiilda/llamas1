
import OpenAI from "openai";
import Kernel from "@onkernel/sdk";
import { killDesktop, getDesktop } from "@/lib/e2b/utils";
import { resolution } from "@/lib/e2b/tool";

// NVIDIA AI Configuration - HARDCODED
const NVIDIA_API_KEY = "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";
const NVIDIA_MODEL = "meta/llama-4-scout-17b-16e-instruct";

// OnKernel Configuration - HARDCODED
const ONKERNEL_API_KEY = "sk_85dd38ea-b33f-45b5-bc33-0eed2357683a.t2lQgq3Lb6DamEGhcLiUgPa1jlx+1zD4BwAdchRHYgA";
const kernelClient = new Kernel({ apiKey: ONKERNEL_API_KEY });

export const runtime = 'nodejs';
export const maxDuration = 3600;
export const dynamic = 'force-dynamic';
export const revalidate = 0;

import { parseTextToolCall } from './route_parser';

// Function to remove computer_use() calls and other technical syntax from text
// MAKSYMALNIE AGRESYWNE FILTROWANIE - usuwa WSZYSTKIE JSONy i fragmenty techniczne
function removeJsonFromText(text: string): string {
  if (!text) return text;
  
  let cleaned = text;
  
  // ETAP 1: ULTRA AGRESYWNE - usu≈Ñ WSZYSTKIE fragmenty zawierajƒÖce { (nawias klamrowy)
  // ≈Åapie wszystko od { do ko≈Ñca linii lub do }
  cleaned = cleaned.replace(/\{[^\}]*$/gm, ' ');  // { bez zamkniƒôcia do ko≈Ñca linii
  cleaned = cleaned.replace(/\{[^\}]*\}/g, ' ');  // { z zamkniƒôciem }
  
  // ETAP 2: Usu≈Ñ fragmenty zaczynajƒÖce siƒô od { nawet bez zamkniƒôcia
  cleaned = cleaned.replace(/\{.*$/gm, ' ');
  
  // ETAP 3: FILTROWANIE WSZYSTKICH WYWO≈ÅA≈É FUNKCJI
  cleaned = cleaned.replace(/computer_use\s*\([^)]*\)/gi, ' ');
  cleaned = cleaned.replace(/bash\s*\([^)]*\)/gi, ' ');
  cleaned = cleaned.replace(/update_workflow\s*\([^)]*\)/gi, ' ');
  cleaned = cleaned.replace(/screenshot\s*\([^)]*\)/gi, ' ');
  
  // ETAP 4: Usu≈Ñ czƒô≈õciowe wywo≈Çania funkcji (bez zamykajƒÖcego nawiasu)
  cleaned = cleaned.replace(/computer_use\s*\(.*$/gi, ' ');
  cleaned = cleaned.replace(/bash\s*\(.*$/gi, ' ');
  cleaned = cleaned.replace(/update_workflow\s*\(.*$/gi, ' ');
  
  // ETAP 5: Usu≈Ñ standalone s≈Çowa kluczowe
  cleaned = cleaned.replace(/\bcomputer_use\b/gi, ' ');
  cleaned = cleaned.replace(/\bupdate_workflow\b/gi, ' ');
  cleaned = cleaned.replace(/\bcomputer\s*$/gmi, ' ');
  
  // ETAP 6: Usu≈Ñ fragmenty z cudzys≈Çowami i dwukropkami (typowe dla JSON)
  cleaned = cleaned.replace(/["'][a-zA-Z_]+["']\s*:\s*["'][^"']*["']/g, ' ');
  cleaned = cleaned.replace(/["'][a-zA-Z_]+["']\s*:/g, ' ');
  
  // ETAP 7: Usu≈Ñ wsp√≥≈Çrzƒôdne i tablice
  cleaned = cleaned.replace(/\[\s*\d+\s*,\s*\d+\s*\]/g, ' ');
  cleaned = cleaned.replace(/\[\s*\d+[^\]]*$/g, ' ');  // niekompletne tablice
  
  // ETAP 8: Usu≈Ñ s≈Çowa kluczowe JSON
  cleaned = cleaned.replace(/["']?name["']?\s*:/gi, ' ');
  cleaned = cleaned.replace(/["']?parameters["']?\s*:/gi, ' ');
  cleaned = cleaned.replace(/["']?action["']?\s*:/gi, ' ');
  cleaned = cleaned.replace(/["']?coordinate["']?\s*:/gi, ' ');
  
  // ETAP 9: Usu≈Ñ komendy specjalne i ich fragmenty
  cleaned = cleaned.replace(/!isfinish/gi, ' ');
  cleaned = cleaned.replace(/!isf[a-z]*/gi, ' ');  // ≈Çapie !isf, !isfi, !isfin, etc.
  cleaned = cleaned.replace(/!is[a-z]*/gi, ' ');   // ≈Çapie !is, !isf, !isfi, etc.
  
  // ETAP 10: Usu≈Ñ fragmenty rozpoczynajƒÖce siƒô od znaku specjalnego
  cleaned = cleaned.replace(/^[\{\["'].*/gm, ' ');
  
  // ETAP 10.5: Usu≈Ñ same nawiasy klamrowe i s≈Çowo assistant
  cleaned = cleaned.replace(/\{assistant/gi, ' ');
  cleaned = cleaned.replace(/\{user/gi, ' ');
  cleaned = cleaned.replace(/\{\s*$/gm, ' ');  // sam { na ko≈Ñcu linii
  cleaned = cleaned.replace(/^\s*\{/gm, ' ');  // sam { na poczƒÖtku linii
  cleaned = cleaned.replace(/\s+\{\s+/g, ' '); // { otoczony spacjami
  
  // ETAP 11: CZYSZCZENIE KO≈ÉCOWE
  // Usu≈Ñ wielokrotne spacje
  cleaned = cleaned.replace(/\s{2,}/g, ' ');
  // Usu≈Ñ puste linie (wiƒôcej ni≈º 2)
  cleaned = cleaned.replace(/\n\s*\n\s*\n/g, '\n\n');
  // Usu≈Ñ leading/trailing whitespace
  cleaned = cleaned.trim();
  
  // ETAP 12: Je≈õli po filtrowaniu zosta≈Ç tylko whitespace, zwr√≥ƒá pustƒÖ string
  if (!cleaned || cleaned.match(/^\s*$/)) {
    return '';
  }
  
  return cleaned;
}

const INSTRUCTIONS = `Jeste≈õ Operatorem - zaawansowanym asystentem AI, kt√≥ry mo≈ºe bezpo≈õrednio kontrolowaƒá przeglƒÖdarkƒô chromium, aby wykonywaƒá zadania u≈ºytkownika.

üî¥ ABSOLUTNIE ZABRONIONE - NIGDY NIE R√ìB TEGO:
- NIGDY nie wysy≈Çaj surowego JSON w wiadomo≈õciach tekstowych do u≈ºytkownika
- NIGDY nie pokazuj u≈ºytkownikowi struktur typu {"action": "screenshot"} w tek≈õcie
- NIGDY nie wypisuj wsp√≥≈Çrzƒôdnych w formacie [512, 384] w wiadomo≈õciach do u≈ºytkownika
- Je≈õli chcesz opisaƒá akcjƒô, pisz normalnym jƒôzykiem: "klikam w pasek adresu" zamiast pokazywaƒá JSON

üî¥ KRYTYCZNIE WA≈ªNE - PRACA KROK PO KROKU:

1. JEDNA AKCJA NA RAZ - Wykonuj TYLKO JEDNƒÑ akcjƒô w jednej odpowiedzi
2. OSOBNE ELEMENTY - Wiadomo≈õƒá tekstowa i akcja to DWA R√ì≈ªNE ELEMENTY - NIGDY NIE ≈ÅƒÑCZ ICH
3. KOLEJNO≈öƒÜ:
   a) Najpierw napisz kr√≥tkƒÖ wiadomo≈õƒá co robisz
   b) Potem wywo≈Çaj JEDNƒÑ akcjƒô computer_use(...)
   c) ZATRZYMAJ SIƒò - poczekaj na wynik
   d) Dopiero po otrzymaniu wyniku (szczeg√≥lnie screenshota) kontynuuj
4. NIGDY NIE PISZ WIELU AKCJI - Tylko jedna computer_use() na odpowied≈∫
5. NIGDY NIE PLANUJ Z WYPRZEDZENIEM - Nie wypisuj ca≈Çego planu akcji, r√≥b krok po kroku

PRZYK≈ÅAD PRAWID≈ÅOWEJ PRACY:
Twoja odpowied≈∫: "Dobra, zaraz zrobiƒô zrzut ekranu ≈ºeby zobaczyƒá co mamy na ekranie.
computer_use("screenshot")"
[SYSTEM WYKONA SCREENSHOT I PRZE≈öLE CI OBRAZ]
Twoja nastƒôpna odpowied≈∫: "Widzƒô przeglƒÖdarkƒô. Teraz kliknƒô w pasek adresu.
computer_use("left_click", 512, 50)"
[SYSTEM WYKONA KLIKNIƒòCIE]
Twoja nastƒôpna odpowied≈∫: computer_use("screenshot")
[itd...]



Twoja rola to **proaktywne dzia≈Çanie** z pe≈ÇnƒÖ transparentno≈õciƒÖ. Zawsze Pisz w stylu bardziej osobistym i narracyjnym. Zamiast suchych i technicznych opis√≥w, prowad≈∫ u≈ºytkownika przez dzia≈Çania w spos√≥b ciep≈Çy, ludzki, opowiadajƒÖcy historiƒô. Zwracaj siƒô bezpo≈õrednio do u≈ºytkownika, a nie jak robot wykonujƒÖcy instrukcje. Tw√≥rz atmosferƒô towarzyszenia, a nie tylko raportowania. M√≥w w czasie tera≈∫niejszym i u≈ºywaj przyjaznych sformu≈Çowa≈Ñ. Tw√≥j styl ma byƒá p≈Çynny, naturalny i przyjazny. Unikaj powtarzania wyra≈ºe≈Ñ technicznych i suchych komunikat√≥w ‚Äî je≈õli musisz podaƒá lokalizacjƒô kursora lub elementu, ubierz to w narracjƒô.

WAZNE!!!!: ZAWSZE ODCZEKAJ CHWILE PO KLIKNIECIU BY DAC CZAS NA ZALADOWANIE SIE 

WAZNE!!!!: ZAWSZE MUSISZ ANALIZOWAC WSZYSTKIE SCREENHOTY - PO KA≈ªDYM SCREENSHOCIE PƒòTLA SIƒò PRZERYWA I DOSTAJESZ OBRAZ. MUSISZ GO PRZEANALIZOWAƒÜ I DOPIERO WTEDY PODJƒÑƒÜ KOLEJNƒÑ AKCJƒò! 

WAZNE!!!!: NIGDY NIE ZGADUJ WSPOLRZEDNYCH JEST TO BEZWZGLEDNIE ZAKAZANE


WA≈ªNE!!!!: MUSISZ BARDZO CZESTO ROBIC ZRZUTY EKRANU BY SPRAWDZAC STAN SANDBOXA - NAJLEPIEJ CO AKCJE!!! ZAWSZE PO KAZDEJ AKCJI ROB ZRZUT EKRANU MUSISZ KONTROLOWAC STAN SANDBOXA

‚ú≥Ô∏è STYL I OSOBOWO≈öƒÜ:

Pisz w stylu narracyjnym, osobistym i ciep≈Çym. Zamiast technicznego raportowania, prowad≈∫ u≈ºytkownika w formie naturalnej rozmowy.
Twoja osobowo≈õƒá jako AI to:

Pozytywna, entuzjastyczna, pomocna, wspierajƒÖca, ciekawska, uprzejma i zaanga≈ºowana.
Masz w sobie ≈ºyczliwo≈õƒá i lekko≈õƒá, ale jeste≈õ te≈º uwa≈ºna i skupiona na zadaniu.
Dajesz u≈ºytkownikowi poczucie bezpiecze≈Ñstwa i komfortu ‚Äî jak przyjaciel, kt√≥ry dobrze siƒô zna na komputerach i z u≈õmiechem pokazuje, co robi.

U≈ºywaj przyjaznych sformu≈Çowa≈Ñ i naturalnego jƒôzyka. Zamiast m√≥wiƒá jak automat (‚ÄûKliknƒô w ikonƒô", "320,80"), m√≥w jak osoba ("Zaraz kliknƒô pasek adresu, ≈ºeby≈õmy mogli co≈õ wpisaƒá").
Tw√≥j jƒôzyk ma byƒá miƒôkki, a narracja ‚Äì p≈Çynna, oparta na tera≈∫niejszo≈õci, swobodna.
Unikaj powtarzania "klikam", "widzƒô", "teraz zrobiƒô" ‚Äî wplataj to w opowie≈õƒá, nie raport.

Absolutnie nigdy nie pisz tylko czysto techniczno, robotycznie - zawsze opowiadaj aktywnie uzytkownikowi, mow cos do uzytkownika, opisuj mu co bedziesz robic, opowiadaj nigdy nie mow czysto robotycznie prowadz tez rozmowe z uzytknownikiem i nie pisz tylko na temat tego co wyjonujesz ale prowadz rowniez aktywna i zaangazowana konwersacje, opowiafaj tez cos uzytkownikowi 


WA≈ªNE: JE≈öLI WIDZISZ CZARNY EKRAN ZAWSZE ODCZEKAJ CHWILE AZ SIE DESKTOP ZANIM RUSZYSZ DALEJ - NIE MOZESZ BEZ TEGO ZACZAC TASKA 

WA≈ªNE ZAWSZE CHWILE ODCZEKAJ PO WYKONANIU AKCJI]


**WERYFIKACJA PO AKCJI:**
- WERYFIKUJ PO KLIKNIƒòCIU: zawsze r√≥b screenshot po klikniƒôciu ≈ºeby sprawdziƒá efekt
- Je≈õli chybione: przeanalizuj gdzie faktycznie kliknƒÖ≈Çe≈õ i popraw wsp√≥≈Çrzƒôdne


### üì∏ ZRZUTY EKRANU - ZASADY 
- R√≥b zrzut ekranu by kontrolowaƒá stan przeglƒÖdarki 
- Po klikniƒôciu, wpisaniu, nawigacji - **natychmiast r√≥b screenshot**
- Je≈õli co≈õ siƒô ≈Çaduje - **poczekaj i zr√≥b screenshot**
- Nigdy nie zak≈Çadaj, ≈ºe co≈õ siƒô uda≈Ço - **ZAWSZE WERYFIKUJ screenshotem**

### üîÑ PROCES DZIA≈ÅANIA
1. Otrzymujesz zadanie od u≈ºytkownika
2. Wy≈õlij wiadomo≈õƒá tekstowƒÖ opisujƒÖcƒÖ plan
3. Zr√≥b screenshot ≈ºeby zobaczyƒá stan desktopa
4. Wykonaj akcjƒô (klikniƒôcie, wpisanie, etc.)
5. Zr√≥b screenshot ≈ºeby zweryfikowaƒá
6. Kontynuuj a≈º zadanie jest wykonane
7. Podsumuj wyniki dla u≈ºytkownika

### üí¨ KOMUNIKACJA
- Zawsze zaczynaj od wiadomo≈õci tekstowej
- Opisuj co robisz w przyjazny spos√≥b
- Informuj o postƒôpach
- Je≈õli co≈õ nie dzia≈Ça - wyja≈õnij i spr√≥buj inaczej

### ‚ö†Ô∏è WA≈ªNE PRZYPOMNIENIA
- przeglƒÖdarka to chromium z rozdzielczo≈õciƒÖ 1024x768
- Zawsze czekaj po klikniƒôciu ≈ºeby strona siƒô za≈Çadowa≈Ça
- R√≥b czƒôste screenshoty ≈ºeby kontrolowaƒá stan
- Nigdy nie zgaduj - zawsze weryfikuj

---

Pamiƒôtaj: Jeste≈õ pomocnym asystentem, kt√≥ry **dzia≈Ça** zamiast tylko m√≥wiƒá. U≈ºytkownicy liczƒÖ na to, ≈ºe wykonasz zadanie, nie tylko je opiszesz. BƒÖd≈∫ proaktywny, transparentny i skuteczny!

**ZAPAMIƒòTAJ WA≈ªNE Rozdzielczo≈õƒá desktop Resolution 1024 x 768 pikseli skala 100% format 4 x 3 system chromium** Oto wsp√≥≈Çrzƒôdne skrajnych punkt√≥w sandboxa rozdzielczo≈õƒá 1024 √ó 768 pikseli

Lewy g√≥rny r√≥g 0 0
Prawy g√≥rny r√≥g 1023 0
Lewy dolny r√≥g 0 767
Prawy dolny r√≥g 1023 767
≈örodek ekranu 512 384
Skrajne granice G√≥ra Y = 0 ca≈Çy g√≥rny brzeg D√≥≈Ç Y = 767 ca≈Çy dolny brzeg Lewo X = 0 ca≈Ça lewa krawƒôd≈∫ Prawo X = 1023 ca≈Ça prawa krawƒôd≈∫
Zakresy X poziomo 0 ‚Üí 1023 lewo ‚Üí prawo Y pionowo 0 ‚Üí 767 g√≥ra ‚Üí d√≥≈Ç
Wa≈ºne Y = 0 to G√ìRA ekranu a Y = 767 to D√ì≈Å Wsp√≥≈Çrzƒôdne zawsze podawane w formacie X Y najpierw poziomo potem pionowo

**DOSTƒòPNE NARZƒòDZIA**

Masz dostƒôp do funkcji computer_use kt√≥ra s≈Çu≈ºy do bezpo≈õredniej interakcji z interfejsem graficznym komputera MUSISZ u≈ºywaƒá tej funkcji za ka≈ºdym razem gdy chcesz wykonaƒá akcjƒô

Dostƒôpne akcje
screenshot wykonuje zrzut ekranu u≈ºywaj CZƒòSTO
left_click klika w podane wsp√≥≈Çrzƒôdne X Y MO≈ªESZ KLIKAƒÜ WSZƒòDZIE Absolutnie ≈ºadnych ogranicze≈Ñ na wsp√≥≈Çrzƒôdne Ca≈Çy ekran jest dostƒôpny
double_click podw√≥jne klikniƒôcie MO≈ªESZ KLIKAƒÜ WSZƒòDZIE bez ogranicze≈Ñ
right_click klikniƒôcie prawym przyciskiem MO≈ªESZ KLIKAƒÜ WSZƒòDZIE bez ogranicze≈Ñ
mouse_move przemieszcza kursor MO≈ªESZ RUSZAƒÜ KURSOREM WSZƒòDZIE bez ogranicze≈Ñ
type wpisuje tekst
key naciska klawisz np enter tab ctrl+c
scroll przewija direction up down scroll_amount liczba klikniƒôƒá
left_click_drag przeciƒÖga start_coordinate + coordinate MO≈ªESZ PRZECIƒÑGAƒÜ WSZƒòDZIE bez ogranicze≈Ñ
wait czeka okre≈õlonƒÖ liczbƒô sekund max 2s

**WA≈ªNE KLIKANIE**
NIE MA ≈ªADNYCH OGRANICZE≈É na wsp√≥≈Çrzƒôdne klikniƒôƒá
Mo≈ºesz klikaƒá w KA≈ªDE miejsce na ekranie 0 0 do max_width-1 max_height-1
Nie unikaj ≈ºadnych obszar√≥w ekranu WSZYSTKO jest klikalne
Je≈õli widzisz element na screenshocie mo≈ºesz w niego kliknƒÖƒá BEZ ≈ªADNYCH WYJƒÑTK√ìW

üî¥ KO≈ÉCZENIE ZADANIA - KOMENDA !isfinish:
Kiedy CA≈ÅKOWICIE UKO≈ÉCZYSZ zadanie u≈ºytkownika i nie ma ju≈º nic wiƒôcej do zrobienia:
1. Wy≈õlij NORMALNƒÑ wiadomo≈õƒá tekstowƒÖ podsumowujƒÖcƒÖ wykonanƒÖ pracƒô
2. Na samym ko≈Ñcu tej wiadomo≈õci napisz: !isfinish
3. To NIE JEST tool ani funkcja - to po prostu tekst na ko≈Ñcu wiadomo≈õci
4. Po wys≈Çaniu tej wiadomo≈õci pƒôtla automatycznie siƒô zako≈Ñczy

PRZYK≈ÅAD PRAWID≈ÅOWY:
"Gotowe! Uda≈Ço mi siƒô znale≈∫ƒá informacje o pogodzie w Warszawie. Temperatura wynosi 15¬∞C, jest pochmurno z mo≈ºliwo≈õciƒÖ deszczu. Wszystkie informacje sƒÖ wy≈õwietlone na ekranie. !isfinish"

B≈ÅƒòDNY PRZYK≈ÅAD (NIE R√ìB TEGO!):
- !isfinish() ‚ùå
- computer_use("!isfinish") ‚ùå
- call_function(!isfinish) ‚ùå

POPRAWNIE: Po prostu napisz !isfinish na ko≈Ñcu swojej ostatniej wiadomo≈õci tekstowej! ‚úÖ

üìã WORKFLOW - DYNAMICZNE ZARZƒÑDZANIE ZADANIEM:

Masz dostƒôp do funkcji update_workflow() kt√≥ra pozwala ci na bie≈ºƒÖco tworzyƒá i aktualizowaƒá plan dzia≈Çania.

**KIEDY U≈ªYWAƒÜ WORKFLOW:**
- Na poczƒÖtku zadania - stw√≥rz workflow z krokami do wykonania
- Gdy odkryjesz nowe informacje - zaktualizuj workflow
- Gdy zmieni siƒô sytuacja - dostosuj kroki
- Gdy uko≈Ñczysz krok - oznacz jako completed i przejd≈∫ dalej

**FORMAT WORKFLOW:**
update_workflow({
  "steps": [
    {"id": 1, "title": "Nazwa kroku", "status": "pending"},
    {"id": 2, "title": "Kolejny krok", "status": "in_progress"},
    {"id": 3, "title": "Nastƒôpny", "status": "completed"}
  ],
  "current_step": 2,
  "notes": "Dodatkowe informacje o postƒôpie"
})

**STATUSY KROK√ìW:**
- pending - do wykonania
- in_progress - aktualnie wykonywany
- completed - uko≈Ñczony
- skipped - pominiƒôty

**PRZYK≈ÅAD U≈ªYCIA:**
1. Otrzymujesz zadanie: "Znajd≈∫ informacje o pogodzie w Warszawie"
2. Tworzysz workflow:
   update_workflow({
     "steps": [
       {"id": 1, "title": "Zrobiƒá screenshot", "status": "in_progress"},
       {"id": 2, "title": "Otworzyƒá Google", "status": "pending"},
       {"id": 3, "title": "Wyszukaƒá pogodƒô Warszawa", "status": "pending"},
       {"id": 4, "title": "Przeanalizowaƒá wyniki", "status": "pending"}
     ],
     "current_step": 1,
     "notes": "Zaczynam od sprawdzenia stanu przeglƒÖdarki"
   })
3. Po wykonaniu kroku - aktualizujesz workflow

**WA≈ªNE:**
- Workflow powinien byƒá elastyczny - mo≈ºesz dodawaƒá/usuwaƒá kroki
- Zawsze aktualizuj workflow gdy sytuacja siƒô zmienia
- U≈ºytkownik widzi workflow w czasie rzeczywistym
- Workflow pomaga u≈ºytkownikowi zrozumieƒá co robisz`;


export async function POST(request: Request) {
  const { messages, sandboxId } = await request.json();

  const desktop = await getDesktop(sandboxId);

  const encoder = new TextEncoder();
  let isStreamClosed = false;
  let messageCounter = 0; // Licznik wiadomo≈õci dla unikalnych ID

  const stream = new ReadableStream({
    async start(controller) {
      const sendEvent = (event: any) => {
        if (isStreamClosed) return;
        try {
          const jsonLine = JSON.stringify(event) + "\n";
          const chunk = encoder.encode(jsonLine);
          controller.enqueue(chunk);
          // Force immediate flush - no buffering
          if ((controller as any).flush) {
            (controller as any).flush();
          }
        } catch (err) {
          console.error("Error sending event:", err);
        }
      };

      const sendText = (text: string) => {
        if (isStreamClosed) return;
        try {
          // Add newline after text so frontend can process it immediately
          const chunk = encoder.encode(text + "\n");
          controller.enqueue(chunk);
          // Force immediate flush - no buffering
          if ((controller as any).flush) {
            (controller as any).flush();
          }
        } catch (err) {
          console.error("Error sending text:", err);
        }
      };

      try {
        const nvidia = new OpenAI({
          apiKey: NVIDIA_API_KEY,
          baseURL: "https://integrate.api.nvidia.com/v1",
        });

        // Clean messages for NVIDIA API compatibility
        const cleanedMessages = messages.map((msg: any) => {
          const { toolCalls, ...cleanMsg } = msg;
          // NVIDIA requires content to be a string, not null/undefined
          if (cleanMsg.content === null || cleanMsg.content === undefined) {
            cleanMsg.content = "";
          }
          // Convert toolCalls (camelCase) to tool_calls (snake_case) for NVIDIA
          if (toolCalls) {
            return { ...cleanMsg, tool_calls: toolCalls };
          }
          return cleanMsg;
        });

        const chatHistory: any[] = [
          { 
            role: "system", 
            content: INSTRUCTIONS
          },
          ...cleanedMessages,
        ];

        // Define tools for function calling
        const tools = [
          {
            type: "function" as const,
            function: {
              name: "computer_use",
              description: "Control the computer desktop by performing actions like clicking, typing, taking screenshots, etc.",
              parameters: {
                type: "object",
                properties: {
                  action: {
                    type: "string",
                    enum: ["screenshot", "left_click", "right_click", "double_click", "mouse_move", "type", "key", "scroll", "wait", "left_click_drag"],
                    description: "The action to perform on the computer"
                  },
                  coordinate: {
                    type: "array",
                    items: { type: "number" },
                    description: "X, Y coordinates for click/move actions (e.g., [512, 384])"
                  },
                  text: {
                    type: "string",
                    description: "Text to type or key to press"
                  },
                  start_coordinate: {
                    type: "array",
                    items: { type: "number" },
                    description: "Starting coordinates for drag action"
                  },
                  delta_x: {
                    type: "number",
                    description: "Horizontal scroll delta"
                  },
                  delta_y: {
                    type: "number",
                    description: "Vertical scroll delta"
                  },
                  duration: {
                    type: "number",
                    description: "Duration in seconds for wait action"
                  }
                },
                required: ["action"]
              }
            }
          },
          {
            type: "function" as const,
            function: {
              name: "update_workflow",
              description: "Update the workflow/plan with current progress and steps",
              parameters: {
                type: "object",
                properties: {
                  steps: {
                    type: "array",
                    items: {
                      type: "object",
                      properties: {
                        id: { type: "number" },
                        title: { type: "string" },
                        status: { 
                          type: "string",
                          enum: ["pending", "in_progress", "completed", "skipped"]
                        }
                      }
                    }
                  },
                  current_step: {
                    type: "number"
                  },
                  notes: {
                    type: "string"
                  }
                },
                required: ["steps"]
              }
            }
          }
        ];

        while (true) {

          const stream = await nvidia.chat.completions.create({
            model: NVIDIA_MODEL,
            messages: chatHistory,
            temperature: 0.7,
            top_p: 0.95,
            stream: true,
            tools: tools,
            tool_choice: "auto",
          });

          let fullText = "";
          let toolCalls: any[] = [];
          let lastSentTextLength = 0; // Track how much text we've already sent

          for await (const chunk of stream) {
            if (chunk.choices && chunk.choices.length > 0) {
              const choice = chunk.choices[0];
              const delta = choice.delta;

              if (delta.content) {
                fullText += delta.content;
                
                // Filter entire fullText accumulated so far
                const filteredFullText = removeJsonFromText(fullText);
                
                // Send only the NEW part (difference from last sent text)
                if (filteredFullText.length > lastSentTextLength) {
                  const newContent = filteredFullText.substring(lastSentTextLength);
                  
                  if (newContent) {
                    sendText(newContent);
                  }
                  
                  lastSentTextLength = filteredFullText.length;
                }
              }

              // Handle tool calls - NVIDIA mo≈ºe zwracaƒá w r√≥≈ºnych formatach
              if (delta.tool_calls) {
                for (const toolCallDelta of delta.tool_calls) {
                  const index = toolCallDelta.index ?? 0;

                  if (!toolCalls[index]) {
                    toolCalls[index] = {
                      id: toolCallDelta.id || `call_${Date.now()}_${index}`,
                      name: "",
                      arguments: "",
                    };
                  }

                  // Update name if provided
                  if (toolCallDelta.function?.name) {
                    toolCalls[index].name = toolCallDelta.function.name;
                  }

                  // Append arguments
                  if (toolCallDelta.function?.arguments) {
                    toolCalls[index].arguments += toolCallDelta.function.arguments;
                  }
                }
              }
            }
          }
          
          // Filter out empty tool calls
          toolCalls = toolCalls.filter(tc => tc && tc.name);
          
          // Fix malformed JSON arguments from NVIDIA streaming
          toolCalls = toolCalls.map(tc => {
            if (tc.arguments) {
              let fixedArgs = tc.arguments;
              
              // Remove any trailing incomplete parts
              fixedArgs = fixedArgs.trim();
              
              // Count braces to find if JSON is incomplete
              const openBraces = (fixedArgs.match(/\{/g) || []).length;
              const closeBraces = (fixedArgs.match(/\}/g) || []).length;
              
              // If more opening braces than closing, add missing closing braces
              if (openBraces > closeBraces) {
                const missing = openBraces - closeBraces;
                fixedArgs += '}'.repeat(missing);
              }
              
              // Fix common NVIDIA streaming bugs:
              // 1. "action": "left_click, "coordinate" -> "action": "left_click", "coordinate"
              fixedArgs = fixedArgs.replace(/"([^"]+)", "([^"]+)": /g, '"$1", "$2": ');
              
              // 2. "coordinate": []512 -> "coordinate": [512
              fixedArgs = fixedArgs.replace(/: \[\](\d)/g, ': [$1');
              
              // 3. [512, 384 -> [512, 384]
              fixedArgs = fixedArgs.replace(/\[(\d+),\s*(\d+)(?!\])/g, '[$1, $2]');
              
              // 4. Ensure arrays are properly closed
              if (fixedArgs.includes('[') && !fixedArgs.includes(']')) {
                const lastBracket = fixedArgs.lastIndexOf('[');
                const afterBracket = fixedArgs.substring(lastBracket + 1);
                // If we have numbers after [, close the array
                if (/\d/.test(afterBracket)) {
                  fixedArgs = fixedArgs.replace(/\[([^\]]+)$/, '[$1]');
                }
              }
              
              // Verify it's valid JSON
              try {
                JSON.parse(fixedArgs);
                tc.arguments = fixedArgs;
              } catch (e) {
                console.error('[JSON FIX ERROR]', e, 'Original:', tc.arguments, 'Fixed:', fixedArgs);
                // If still invalid, try to salvage what we can
                // Extract action at minimum
                const actionMatch = tc.arguments.match(/"action":\s*"([^"]+)"/);
                if (actionMatch) {
                  const action = actionMatch[1];
                  
                  // Try to extract coordinate if present
                  const coordMatch = tc.arguments.match(/(\d+),\s*(\d+)/);
                  if (coordMatch && (action.includes('click') || action.includes('move'))) {
                    tc.arguments = JSON.stringify({
                      action: action,
                      coordinate: [parseInt(coordMatch[1]), parseInt(coordMatch[2])]
                    });
                  } else if (action === 'screenshot' || action === 'wait') {
                    tc.arguments = JSON.stringify({ action: action });
                  } else {
                    // Try to extract text
                    const textMatch = tc.arguments.match(/"text":\s*"([^"]+)"/);
                    if (textMatch) {
                      tc.arguments = JSON.stringify({
                        action: action,
                        text: textMatch[1]
                      });
                    } else {
                      tc.arguments = JSON.stringify({ action: action });
                    }
                  }
                }
              }
            }
            return tc;
          });
          

          let textBeforeAction = "";
          if (toolCalls.length === 0 && fullText) {
            const parsed = parseTextToolCall(fullText);
            if (parsed) {
              toolCalls = [parsed.toolCall];
              textBeforeAction = parsed.textBefore;
            }
          }

          // Check if AI wants to finish - look for !isfinish command
          const wantsToFinish = fullText && fullText.includes('!isfinish');

          if (toolCalls.length > 0) {
            // AI is calling tools - EXECUTE ONLY FIRST ONE, then break loop
            // This ensures ONE action per iteration
            const firstToolCall = toolCalls[0];
            
            // KROK 1: Wy≈õlij finish event aby frontend zamknƒÖ≈Ç obecnƒÖ wiadomo≈õƒá tekstowƒÖ
            // (tekst zosta≈Ç ju≈º wystreamowany przez sendText)
            sendEvent({
              type: "finish",
            });
            
            messageCounter++;
            
            // KROK 2: Dodaj tekst do historii czatu (tylko je≈õli by≈Ç)
            if (textBeforeAction && textBeforeAction.trim()) {
              chatHistory.push({
                role: "assistant",
                content: textBeforeAction,
              });
            } else if (fullText && fullText.trim()) {
              // Je≈õli nie by≈Ço parsed textBefore, u≈ºyj pe≈Çnego tekstu
              const filteredText = removeJsonFromText(fullText);
              if (filteredText && filteredText.trim()) {
                chatHistory.push({
                  role: "assistant",
                  content: filteredText,
                });
              }
            }
            
            // KROK 3: Przygotuj tool call message - JAKO OSOBNA WIADOMO≈öƒÜ
            messageCounter++;
            
            const assistantMessage: any = {
              role: "assistant",
              content: "",  // NO TEXT HERE - action only
              tool_calls: [{
                id: firstToolCall.id,
                type: "function",
                function: {
                  name: firstToolCall.name,
                  arguments: firstToolCall.arguments,
                },
              }],
            };
            chatHistory.push(assistantMessage);

            const toolCall = firstToolCall;
            const parsedArgs = JSON.parse(toolCall.arguments);
            const toolName = toolCall.name === "computer_use" ? "computer" : (toolCall.name === "update_workflow" ? "workflow" : "bash");

            sendEvent({
              type: "tool-input-available",
              toolCallId: toolCall.id,
              toolName: toolName,
              input: parsedArgs,
            });

            let screenshotData: any = null;
            const toolResult = await (async () => {
              try {
                let resultData: any = { type: "text", text: "" };
                let resultText = "";

                if (toolCall.name === "computer_use") {
                  const action = parsedArgs.action;

                  switch (action) {
                    case "screenshot": {
                      const response = await kernelClient.browsers.computer.captureScreenshot(desktop.session_id);
                      const blob = await response.blob();
                      const buffer = Buffer.from(await blob.arrayBuffer());
                      
                      const timestamp = new Date().toISOString();
                      const width = resolution.x;
                      const height = resolution.y;
                      const base64Image = buffer.toString("base64");

                      screenshotData = {
                        type: "image",
                        data: base64Image,
                        timestamp: timestamp,
                        width: width,
                        height: height
                      };

                      // Format for Vision API - include image in content
                      resultText = `Screenshot taken at ${timestamp}

SCREEN: ${width}√ó${height} pixels | Aspect ratio: 4:3 | Origin: (0,0) at TOP-LEFT
‚ö†Ô∏è  REMEMBER: Y=0 is at TOP, Y increases DOWNWARD (0‚Üí767)
‚ö†Ô∏è  FORMAT: [X, Y] - horizontal first, then vertical
‚ö†Ô∏è  SZCZEG√ì≈ÅOWA ANALIZA WYMAGANA: Przeanalizuj dok≈Çadnie screenshot przed kolejnymi akcjami!`;

                      resultData = {
                        type: "image",
                        data: base64Image,
                      };

                      sendEvent({
                        type: "screenshot-update",
                        screenshot: base64Image,
                      });
                      break;
                    }
                    case "wait": {
                      const duration = parsedArgs.duration || 1;
                      resultText = `Waited for ${duration} seconds`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "left_click": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.clickMouse(desktop.session_id, {
                        x: Math.round(x),
                        y: Math.round(y),
                        button: 'left',
                      });
                      resultText = `Left clicked at coordinates (${Math.round(x)}, ${Math.round(y)})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "double_click": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.clickMouse(desktop.session_id, {
                        x: Math.round(x),
                        y: Math.round(y),
                        button: 'left',
                        num_clicks: 2,
                      });
                      resultText = `Double clicked at coordinates (${Math.round(x)}, ${Math.round(y)})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "right_click": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.clickMouse(desktop.session_id, {
                        x: Math.round(x),
                        y: Math.round(y),
                        button: 'right',
                      });
                      resultText = `Right clicked at coordinates (${Math.round(x)}, ${Math.round(y)})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "mouse_move": {
                      const [x, y] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.moveMouse(desktop.session_id, {
                        x: Math.round(x),
                        y: Math.round(y),
                      });
                      resultText = `Moved mouse to ${Math.round(x)}, ${Math.round(y)}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "type": {
                      const textToType = parsedArgs.text;
                      await kernelClient.browsers.computer.typeText(desktop.session_id, {
                        text: textToType,
                      });
                      resultText = `Typed: ${textToType}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "key": {
                      let keyToPress = parsedArgs.text;
                      
                      // OnKernel uses X11 keysym names - convert common variants to X11 format
                      if (keyToPress === "Enter" || keyToPress === "enter") {
                        keyToPress = "Return";
                      }
                      
                      
                      await kernelClient.browsers.computer.pressKey(desktop.session_id, {
                        keys: [keyToPress],
                      });
                      resultText = `Pressed key: ${parsedArgs.text}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "scroll": {
                      const [x, y] = parsedArgs.coordinate || [512, 384];
                      const delta_x = parsedArgs.delta_x || 0;
                      const delta_y = parsedArgs.delta_y || 0;
                      await kernelClient.browsers.computer.scroll(desktop.session_id, {
                        x: Math.round(x),
                        y: Math.round(y),
                        delta_x: Math.round(delta_x),
                        delta_y: Math.round(delta_y),
                      });
                      resultText = `Scrolled at (${Math.round(x)}, ${Math.round(y)}) with delta_x: ${Math.round(delta_x)}, delta_y: ${Math.round(delta_y)}`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    case "left_click_drag": {
                      const [startX, startY] = parsedArgs.start_coordinate;
                      const [endX, endY] = parsedArgs.coordinate;
                      await kernelClient.browsers.computer.dragMouse(desktop.session_id, {
                        path: [[Math.round(startX), Math.round(startY)], [Math.round(endX), Math.round(endY)]],
                        button: 'left',
                      });
                      resultText = `Dragged from (${Math.round(startX)}, ${Math.round(startY)}) to (${Math.round(endX)}, ${Math.round(endY)})`;
                      resultData = { type: "text", text: resultText };
                      break;
                    }
                    default: {
                      resultText = `Unknown action: ${action}`;
                      resultData = { type: "text", text: resultText };
                      console.warn("Unknown action:", action);
                    }
                  }

                  sendEvent({
                    type: "tool-output-available",
                    toolCallId: toolCall.id,
                    output: resultData,
                  });

                  return {
                    tool_call_id: toolCall.id,
                    role: "tool",
                    content: resultText,
                    image: action === "screenshot" ? resultData.data : undefined,
                  };
                } else if (toolCall.name === "update_workflow") {
                  // Handle workflow updates
                  const workflowData = parsedArgs;
                  
                  // Send workflow update event to frontend
                  sendEvent({
                    type: "workflow-update",
                    workflow: workflowData,
                    timestamp: new Date().toISOString(),
                  });

                  sendEvent({
                    type: "tool-output-available",
                    toolCallId: toolCall.id,
                    output: { type: "text", text: "Workflow updated" },
                  });

                  return {
                    tool_call_id: toolCall.id,
                    role: "tool",
                    content: "Workflow updated successfully. Continue with the next action.",
                  };
                } else if (toolCall.name === "bash_command") {
                  const result = await kernelClient.browsers.process.exec(desktop.session_id, {
                    command: parsedArgs.command,
                  });

                  const stdout = result.stdout_b64 ? Buffer.from(result.stdout_b64, 'base64').toString('utf-8') : '';
                  const stderr = result.stderr_b64 ? Buffer.from(result.stderr_b64, 'base64').toString('utf-8') : '';
                  const output = stdout || stderr || "(Command executed successfully with no output)";

                  sendEvent({
                    type: "tool-output-available",
                    toolCallId: toolCall.id,
                    output: { type: "text", text: output },
                  });

                  return {
                    tool_call_id: toolCall.id,
                    role: "tool",
                    content: output,
                  };
                }
              } catch (error) {
                console.error("Error executing tool:", error);
                const errorMsg = error instanceof Error ? error.message : String(error);
                let detailedError = `Error: ${errorMsg}`;

                if (errorMsg.includes('Failed to type')) {
                  detailedError += '\n\nSuggestion: The text field might not be active. Try clicking on the text field first before typing.';
                } else if (errorMsg.includes('Failed to click') || errorMsg.includes('Failed to double click') || errorMsg.includes('Failed to right click')) {
                  detailedError += '\n\nSuggestion: The click action failed. Take a screenshot to see what happened, then try clicking again.';
                } else if (errorMsg.includes('Failed to take screenshot')) {
                  detailedError += '\n\nSuggestion: Screenshot failed. The desktop might be loading. Wait a moment and try again.';
                } else if (errorMsg.includes('Failed to press key')) {
                  detailedError += '\n\nSuggestion: Key press failed. Make sure the correct window is focused.';
                } else if (errorMsg.includes('Failed to move mouse')) {
                  detailedError += '\n\nSuggestion: Mouse movement failed. Try again.';
                } else if (errorMsg.includes('Failed to drag')) {
                  detailedError += '\n\nSuggestion: Drag operation failed. Try again with different coordinates.';
                } else if (errorMsg.includes('Failed to scroll')) {
                  detailedError += '\n\nSuggestion: Scroll failed. Make sure a scrollable window is active.';
                }

                sendEvent({
                  type: "error",
                  errorText: errorMsg,
                });

                return {
                  tool_call_id: toolCall.id,
                  role: "tool",
                  content: detailedError,
                };
              }
            })();

            // Send tool result to chat history
            // Format tool result message
            let toolMessage: any;
            if (screenshotData) {
              // KRYTYCZNE: Screenshot jako TOOL MESSAGE (potwierdzenie akcji)
              toolMessage = {
                role: "tool",
                tool_call_id: toolResult!.tool_call_id,
                content: `Screenshot captured successfully at ${screenshotData.timestamp}`
              };
              chatHistory.push(toolMessage);
              
              // KRYTYCZNE: Screenshot jako USER MESSAGE (obraz do analizy)
              // To sprawi ≈ºe AI bƒôdzie musia≈Ç odpowiedzieƒá analizujƒÖc obraz
              const userScreenshotMessage = {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: `Oto screenshot z sandboxa. Przeanalizuj go dok≈Çadnie przed podjƒôciem kolejnej akcji.\n\nSCREEN: ${screenshotData.width}√ó${screenshotData.height} pixels | Aspect ratio: 4:3 | Origin: (0,0) at TOP-LEFT\n‚ö†Ô∏è REMEMBER: Y=0 is at TOP, Y increases DOWNWARD (0‚Üí767)\n‚ö†Ô∏è FORMAT: [X, Y] - horizontal first, then vertical\n‚ö†Ô∏è CO WIDZISZ NA TYM SCREENSHOCIE? OPISZ I PODEJMIJ DECYZJƒò O KOLEJNEJ AKCJI.`
                  },
                  {
                    type: "image_url",
                    image_url: {
                      url: `data:image/png;base64,${screenshotData.data}`
                    }
                  }
                ]
              };
              chatHistory.push(userScreenshotMessage);
            } else {
              toolMessage = {
                role: "tool",
                tool_call_id: toolResult!.tool_call_id,
                content: toolResult!.content,
              };
              chatHistory.push(toolMessage);
            }        
            // INFINITE LOOP: Po akcji kontynuujemy automatycznie bez delay√≥w
            
          } else {
            // No tool calls - AI is just sending text
            if (fullText) {
              messageCounter++;
              
              // Normal text message - add to history and continue loop
              chatHistory.push({
                role: "assistant",
                content: fullText,
              });
              
              // Check if AI wants to finish - komenda !isfinish jest ju≈º w tek≈õcie
              // Po prostu ko≈Ñczymy pƒôtlƒô
              if (wantsToFinish) {
                break;
              }
            }
            
            // Continue loop - AI will execute next action or send another message
          }
        }
      } catch (error) {
        console.error("Chat API error:", error);
        await killDesktop(sandboxId);
        sendEvent({
          type: "error",
          errorText: String(error),
        });
      } finally {
        if (!isStreamClosed) {
          isStreamClosed = true;
          controller.close();
        }
      }
    },
  });

  return new Response(stream, {
    headers: {
      "Content-Type": "text/plain; charset=utf-8",
      "Cache-Control": "no-cache, no-store, must-revalidate, max-age=0",
      "Pragma": "no-cache",
      "Expires": "0",
      "X-Accel-Buffering": "no",
      "Transfer-Encoding": "chunked",
      "Connection": "keep-alive",
    },
  });
}
